import streamlit as st
import requests
import pandas as pd
import json
import base64
import io
import time

# URL base de tu API de modelos (FastAPI)
# Usamos el nombre del servicio Docker 'model-api' y el puerto 8000
FASTAPI_BASE_URL = "http://model-api:8000"

st.set_page_config(layout="wide", page_title="Sistema de ML Distribuido con Ray")

st.title("üìä Sistema de Machine Learning Distribuido con Ray")
st.markdown("Una interfaz para gestionar, monitorizar y visualizar modelos de ML entrenados con Ray y servidos con FastAPI.")

# --- Funci√≥n para llamar a la API ---
def call_api(endpoint, method="GET", data=None):
    url = f"{FASTAPI_BASE_URL}/{endpoint}"
    try:
        if method == "GET":
            response = requests.get(url)
        elif method == "POST":
            response = requests.post(url, json=data)
        response.raise_for_status() # Lanza un error para c√≥digos de estado HTTP 4xx/5xx
        return response.json()
    except requests.exceptions.ConnectionError:
        st.error(f"Error de conexi√≥n: No se pudo conectar con el servicio FastAPI en {FASTAPI_BASE_URL}. Aseg√∫rate de que el contenedor 'model-api' est√© corriendo.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"Error al llamar a la API en {endpoint}: {e}")
        if response and response.content:
            try:
                st.error(f"Detalles del error de la API: {response.json()}")
            except json.JSONDecodeError:
                st.error(f"Respuesta de error no JSON: {response.text}")
        return None

# --- Barra lateral para navegaci√≥n ---
st.sidebar.header("Navegaci√≥n")
page = st.sidebar.radio("Ir a", ["Estado del Sistema", "M√©tricas de Entrenamiento", "Predicci√≥n de Modelos", "Monitoreo de Inferencia", "Visualizaci√≥n de Gr√°ficas"])

# --- Secci√≥n: Estado del Sistema ---
if page == "Estado del Sistema":
    st.header("Estado General del Sistema")
    health_data = call_api("health")
    if health_data:
        st.success("Servicio FastAPI en l√≠nea y saludable.")
        st.json(health_data)

    st.subheader("Modelos Disponibles")
    models_data = call_api("models")
    if models_data and models_data.get("available_models"):
        st.write(f"Total de modelos cargados: {models_data['total_models']}")
        st.write("Lista de modelos:")
        for model_name in models_data['available_models']:
            st.markdown(f"- **{model_name}**")
    elif models_data:
        st.warning("No se encontraron modelos cargados. Aseg√∫rate de que 'train.py' se haya ejecutado correctamente.")

# --- Secci√≥n: M√©tricas de Entrenamiento ---
elif page == "M√©tricas de Entrenamiento":
    st.header("M√©tricas de Entrenamiento de Modelos")
    all_metadata = call_api("all-models-metadata")
    if all_metadata:
        st.subheader("Resumen de M√©tricas por Modelo")
        metrics_df_data = []
        for model_name, metadata in all_metadata.items():
            if "error" in metadata:
                metrics_df_data.append({"Modelo": model_name, "Estado": "Error al cargar m√©tricas", "Detalle": metadata["error"]})
                continue
            
            metrics = metadata.get("metrics", {})
            metrics_df_data.append({
                "Modelo": model_name,
                "Accuracy": f"{metrics.get('accuracy', 0):.4f}",
                "Precision": f"{metrics.get('precision', 0):.4f}",
                "Recall": f"{metrics.get('recall', 0):.4f}",
                "F1-Score": f"{metrics.get('f1_score', 0):.4f}",
                "ROC AUC": f"{metrics.get('roc_auc', 0):.4f}" if metrics.get('roc_auc') is not None else "N/A",
                "Fecha Entrenamiento": metadata.get("training_date", "N/A").split('T')[0]
            })
        
        metrics_df = pd.DataFrame(metrics_df_data)
        st.dataframe(metrics_df, use_container_width=True)

        st.subheader("Detalle de M√©tricas por Modelo")
        selected_model_metrics = st.selectbox("Selecciona un modelo para ver el detalle de sus m√©tricas:", list(all_metadata.keys()))
        if selected_model_metrics:
            st.json(all_metadata[selected_model_metrics])

# --- Secci√≥n: Predicci√≥n de Modelos ---
elif page == "Predicci√≥n de Modelos":
    st.header("Realizar Predicciones")
    models_data = call_api("models")
    if models_data and models_data.get("available_models"):
        model_names = models_data['available_models']
        selected_model = st.selectbox("Selecciona un modelo para predecir:", model_names)

        if selected_model:
            st.subheader(f"Caracter√≠sticas para {selected_model}")
            # Aqu√≠ definimos las caracter√≠sticas esperadas para el dataset Titanic
            # Adapta esto si tu dataset es diferente
            features = {}
            st.write("Introduce las caracter√≠sticas del pasajero:")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                features["Pclass"] = st.selectbox("Clase de Pasajero (Pclass):", [1, 2, 3], index=2)
                features["Sex"] = st.selectbox("Sexo:", ["male", "female"], index=0)
                features["Age"] = st.number_input("Edad:", min_value=0.0, max_value=100.0, value=25.0)
            with col2:
                features["SibSp"] = st.number_input("N√∫mero de hermanos/c√≥nyuges a bordo (SibSp):", min_value=0, value=0)
                features["Parch"] = st.number_input("N√∫mero de padres/hijos a bordo (Parch):", min_value=0, value=0)
                features["Fare"] = st.number_input("Tarifa (Fare):", min_value=0.0, value=32.20)
            with col3:
                features["Embarked"] = st.selectbox("Puerto de Embarque (Embarked):", ["C", "Q", "S"], index=2)
            
            # Puedes a√±adir m√°s caracter√≠sticas seg√∫n tu dataset
            # Ejemplo: features["Cabin"] = st.text_input("Cabina (Cabin):", "N/A")
            # Ejemplo: features["Name"] = st.text_input("Nombre (Name):", "John Doe")

            if st.button("Obtener Predicci√≥n"):
                prediction_data = call_api(f"predict/{selected_model}", method="POST", data={"features": features})
                if prediction_data:
                    st.success("Predicci√≥n Exitosa!")
                    st.json(prediction_data)
                    st.info(f"Latencia de la predicci√≥n: {prediction_data.get('latency_ms', 0):.2f} ms")
    else:
        st.warning("No hay modelos disponibles para predicci√≥n. Entrena algunos modelos primero.")

# --- Secci√≥n: Monitoreo de Inferencia ---
elif page == "Monitoreo de Inferencia":
    st.header("Monitoreo de Inferencia en Producci√≥n")
    st.write("Estad√≠sticas de uso de los modelos y latencia promedio.")

    inference_stats = call_api("inference-stats")
    if inference_stats:
        st.subheader("Resumen de Estad√≠sticas de Inferencia")
        stats_df_data = []
        for model_name, stats in inference_stats.items():
            stats_df_data.append({
                "Modelo": model_name,
                "Total Solicitudes": stats.get('total_requests', 0),
                "Latencia Promedio (ms)": f"{stats.get('average_latency_ms', 0):.2f}"
            })
        stats_df = pd.DataFrame(stats_df_data)
        st.dataframe(stats_df, use_container_width=True)

        st.subheader("Detalle de Latencias Recientes (√öltimas 100)")
        selected_model_latency = st.selectbox("Selecciona un modelo para ver sus latencias recientes:", list(inference_stats.keys()))
        if selected_model_latency and inference_stats[selected_model_latency].get('last_100_latencies_ms'):
            latencies = inference_stats[selected_model_latency]['last_100_latencies_ms']
            st.line_chart(pd.DataFrame({"Latencia (ms)": latencies}))
        elif selected_model_latency:
            st.info("No hay datos de latencia recientes para este modelo a√∫n.")
    else:
        st.info("No hay estad√≠sticas de inferencia disponibles a√∫n. Realiza algunas predicciones.")

# --- Secci√≥n: Visualizaci√≥n de Gr√°ficas ---
elif page == "Visualizaci√≥n de Gr√°ficas":
    st.header("Visualizaci√≥n de Gr√°ficas de Rendimiento")
    models_data = call_api("models")
    if models_data and models_data.get("available_models"):
        model_names = models_data['available_models']
        selected_model_plot = st.selectbox("Selecciona un modelo para ver sus gr√°ficas:", model_names)

        if selected_model_plot:
            st.subheader(f"Curva ROC para {selected_model_plot}")
            roc_png_data = call_api(f"model-roc-png/{selected_model_plot}")
            if roc_png_data and roc_png_data.get("image_base64"):
                st.image(base64.b64decode(roc_png_data["image_base64"]), caption=f"Curva ROC para {selected_model_plot}", use_column_width=True)
            else:
                st.warning(roc_png_data.get("error", "No se pudo cargar la Curva ROC. Aseg√∫rate de que el modelo soporte predict_proba y que los datos de prueba est√©n disponibles."))

            st.subheader(f"Curva de Aprendizaje para {selected_model_plot}")
            learning_png_data = call_api(f"model-learning-curve-png/{selected_model_plot}")
            if learning_png_data and learning_png_data.get("image_base64"):
                st.image(base64.b64decode(learning_png_data["image_base64"]), caption=f"Curva de Aprendizaje para {selected_model_plot}", use_column_width=True)
            else:
                st.warning(learning_png_data.get("error", "No se pudo cargar la Curva de Aprendizaje. Aseg√∫rate de que los datos de entrenamiento est√©n disponibles."))
    else:
        st.warning("No hay modelos disponibles para generar gr√°ficas. Entrena algunos modelos primero.")

st.sidebar.markdown("---")
st.sidebar.info("Desarrollado con Ray, FastAPI y Streamlit.")
