import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import time
import os 
import json

FASTAPI_BASE_URL = os.getenv("FASTAPI_URL", "http://localhost:8000")
st.sidebar.info(f"Conectando a FastAPI en: {FASTAPI_BASE_URL}")

def get_available_models():
    """Obtiene la lista de modelos disponibles desde la API de FastAPI."""
    try:
        response = requests.get(f"{FASTAPI_BASE_URL}/models")
        response.raise_for_status()  
        return response.json().get("available_models", [])
    except requests.exceptions.ConnectionError:
        st.error(f"Error de conexi√≥n: Aseg√∫rate de que la API de FastAPI est√© corriendo en {FASTAPI_BASE_URL}")
        return []
    except requests.exceptions.RequestException as e:
        st.error(f"Error al obtener modelos: {e}")
        return []

def get_all_models_metadata():
    """Obtiene los metadatos de todos los modelos desde la API de FastAPI."""
    try:
        response = requests.get(f"{FASTAPI_BASE_URL}/all-models-metadata")
        response.raise_for_status()
        return response.json()
    except requests.exceptions.ConnectionError:
        st.error(f"Error de conexi√≥n: Aseg√∫rate de que la API de FastAPI est√© corriendo en {FASTAPI_BASE_URL}")
        return {}
    except requests.exceptions.RequestException as e:
        st.error(f"Error al obtener metadatos: {e}")
        return {}

def make_prediction(model_name: str, features: dict):
    """Realiza una predicci√≥n para un modelo dado con las caracter√≠sticas proporcionadas."""
    try:
        response = requests.post(f"{FASTAPI_BASE_URL}/predict/{model_name}", json={"features": features})
        response.raise_for_status()
        return response.json()
    except requests.exceptions.ConnectionError:
        st.error(f"Error de conexi√≥n: Aseg√∫rate de que la API de FastAPI est√© corriendo en {FASTAPI_BASE_URL}")
        return None
    except requests.exceptions.HTTPError as e:
        st.error(f"Error de la API al predecir: {e.response.json().get('detail', str(e))}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"Error inesperado al predecir: {e}")
        return None

st.set_page_config(layout="wide", page_title="M√©tricas de Rendimiento de Modelos ML")

st.title("M√©tricas de Rendimiento de Modelos de ML entrenados con Ray")
st.markdown("""
Esta aplicaci√≥n de Streamlit se conecta a la API de FastAPI para obtener y visualizar m√©tricas de rendimiento y realizar predicciones con los modelos de Machine Learning desplegados en Ray.
""")

st.header("‚ú® Modelos Disponibles")
available_models = get_available_models()
if available_models:
    st.success(f"Modelos conectados y disponibles: {', '.join(available_models)}")
else:
    st.warning("No se encontraron modelos disponibles. Aseg√∫rate de que la API de FastAPI est√© funcionando y los actores de Ray est√©n registrados.")

st.header("üìà Metadatos de Entrenamiento y Rendimiento")
all_metadata = get_all_models_metadata()

if all_metadata:
    metadata_rows = []

    chart_metrics_data = {} 

    for model_name, data in all_metadata.items():
        if "error" in data:
            metadata_rows.append({
                "Modelo": model_name, 
                "Estado": data["error"], 
                "Precisi√≥n (Accuracy)": "N/A", 
                "Recall": "N/A",
                "F1 Score": "N/A",
            })
            chart_metrics_data[model_name] = {
                "Precisi√≥n (Accuracy)": None,
                "Recall": None,
                "F1 Score": None
            }
        else:
            metrics = data.get("metrics", {}) 
            
            accuracy = metrics.get("accuracy", "N/A")
            recall = metrics.get("recall", "N/A")
            f1_score = metrics.get("f1_score", "N/A")
            
            metadata_rows.append({
                "Modelo": model_name,
                "Estado": "Cargado",
                "Precisi√≥n (Accuracy)": f"{accuracy:.4f}" if isinstance(accuracy, (int, float)) else accuracy,
                "Recall": f"{recall:.4f}" if isinstance(recall, (int, float)) else recall,
                "F1 Score": f"{f1_score:.4f}" if isinstance(f1_score, (int, float)) else f1_score,
            })
            
            chart_metrics_data[model_name] = {
                "Precisi√≥n (Accuracy)": accuracy if isinstance(accuracy, (int, float)) else None,
                "Recall": recall if isinstance(recall, (int, float)) else None,
                "F1 Score": f1_score if isinstance(f1_score, (int, float)) else None
            }

    df_metadata = pd.DataFrame(metadata_rows)
    st.dataframe(df_metadata, use_container_width=True)

    st.subheader("Comparaci√≥n de M√©tricas de Rendimiento")

    metric_options = ["Precisi√≥n (Accuracy)", "Recall", "F1 Score"]
    selected_metric = st.selectbox("Selecciona la m√©trica para comparar:", metric_options)

    chart_data_rows = []
    has_chart_data = False
    for model_name, metrics_values in chart_metrics_data.items():
        metric_value = metrics_values.get(selected_metric)
        if metric_value is not None: 
            chart_data_rows.append({"Modelo": model_name, "Valor de la M√©trica": metric_value})
            has_chart_data = True

    if has_chart_data:
        df_chart = pd.DataFrame(chart_data_rows)
        
        fig = px.bar(df_chart, x='Modelo', y='Valor de la M√©trica',
                        title=f'{selected_metric} de los Modelos Entrenados',
                        labels={'Valor de la M√©trica': selected_metric},
                        color='Modelo',
                        template='plotly_white')
        fig.update_layout(xaxis_title="Modelo", yaxis_title=selected_metric)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info(f"No hay datos num√©ricos de '{selected_metric}' disponibles para graficar.")
else:
    st.info("No se pudieron cargar los metadatos de los modelos.")

st.header("üîÆ Predicci√≥n")

if available_models:
    selected_model = st.selectbox("Selecciona un modelo para predecir:", available_models)

    st.markdown("""
    Introduce las caracter√≠sticas de entrada para la predicci√≥n.
    """)

    st.subheader("Input (JSON)")
    default_features_example = {
        "Pclass": 3,
        "Sex": "female",
        "Age": 20,
        "SibSp": 1,
        "Parch": 0,
        "Fare": 7.50,
        "Embarked": "S"
    }
    
    features_input = st.text_area(
        "Introduce las caracter√≠sticas:",
        value=json.dumps(default_features_example, indent=2),
        height=200
    )

    predict_button = st.button("Realizar Predicci√≥n")

    if predict_button:
        try:
            features = json.loads(features_input)
            if not isinstance(features, dict):
                st.error("El input JSON debe ser un objeto (diccionario) de caracter√≠sticas.")
            else:
                with st.spinner(f"Realizando predicci√≥n con {selected_model}..."):
                    prediction_response = make_prediction(selected_model, features)
                    if prediction_response:
                        st.subheader("Resultados de la Predicci√≥n:")
                        st.json(prediction_response)
                        st.info(f"Latencia de la predicci√≥n: {prediction_response.get('latency_ms', 'N/A'):.2f} ms")
        except json.JSONDecodeError:
            st.error("Error: El formato JSON de las caracter√≠sticas es inv√°lido. Por favor, revisa la sintaxis.")
        except Exception as e:
            st.error(f"Ocurri√≥ un error inesperado al procesar la predicci√≥n: {e}")
else:
    st.info("No hay modelos disponibles para realizar predicciones.")
